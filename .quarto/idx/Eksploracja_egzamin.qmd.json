{"title":"Eksploracja Danych","markdown":{"headingText":"Eksploracja Danych","headingAttr":{"id":"","classes":["unnumbered"],"keyvalue":[]},"containsRefs":false,"markdown":"\n---\ntitle: \"Eksploracja Danych\"\nauthor: \"Michał Koziński\"\nformat: \n  html:\n    toc: true\n    <!-- embed-resources: true -->\n    <!-- self-contained: true -->\n    page-layout: full\ndate: \"06-22-2023\"\n---\n\n# Zagadnienia do przygotowania na egzamin ustny z Eksploracji Danych\n\n___\n\n## 1. Opisz etapy eksploracji danych.\n\n![](obrazki/dm_stages.jpg)\n\n1. Czyszczenie danych - polega na usuwaniu braków danych, usuwaniu stałych zmiennych, imputacji braków danych oraz przygotowaniu danych do dalszych analiz.\n\n2. Integracja danych - łączenie danych pochodzących z różnych źródeł.\n\n3. Selekcja danych - wybór z bazy tych danych, które są potrzebne do dalszych analiz.\n\n4. Transformacja danych - przekształcenie i konsolidacja danych do postaci przydatnej do eksploracji.\n\n5. Eksploracja danych - zastosowanie technik wymienionych wcześniej w celu odnalezienia wzorców i zależności.\n\n6. Ewaluacja modeli - ocena poprawności modeli oraz wzorców z nich uzyskanych.\n\n7. Wizualizacja wyników - graficzne przedstawienie odkrytych wzorców.\n\n8. Wdrażanie modeli - zastosowanie wyznaczonych wzorców.\n\n<br>\n\n## 2. Na czym polega imputacja danych? Wymień trzy metody imputacji.\n\nZastępowanie braków danych (zwane także imputacją danych) jest etapem procesu przygotowania danych do analiz. Nie można jednak wyróżnić uniwersalnego sposobu zastępowania braków dla wszystkich możliwych sytuacji. Wśród statystyków panuje przekonanie, że w przypadku wystąpienia braków danych można zastosować trzy strategie:\n\n* **nic nie robić z brakami** - co wydaje się niedorzeczne ale wcale takie nie jest, ponieważ istnieje wiele modeli statystycznych (np. drzewa decyzyjne), które świetnie radzą sobie w sytuacji braków danych. Niestety nie jest to sposób, który można stosować zawsze, ponieważ są również modele wymagające kompletności danych jak na przykład sieci neuronowe.\n\n* **usuwać braki wierszami** - to metoda, która jest stosowana domyślnie w przypadku kiedy twórca modelu nie zadecyduje o innym sposobie obsługi luk. Metoda ta ma swoją niewątpliwą zaletę w postaci jasnej i prostej procedury, ale szczególnie w przypadku niewielkich zbiorów może skutkować obciążeniem estymatorów. Nie wiemy bowiem jaka wartość faktycznie jest przypisana danej cesze. Jeśli jest to wartość bliska np. średniej, to nie wpłynie znacząco na obciążenie estymatora wartości oczekiwanej. W przypadku, gdy różni się ona znacznie od średniej tej cechy, to estymator może już wykazywać obciążenie. Jego wielkość zależy również od liczby usuniętych elementów. Nie jest zalecane usuwanie wielu wierszy ze zbioru danych i na podstawie okrojonego zbioru wyciąganie wniosków o populacji, ponieważ próba jest wówczas znacząco inna niż populacja. Dodatkowo jeśli estymatory są wyznaczane na podstawie zbioru wyraźnie mniej licznego, to precyzja estymatorów wyrażona wariancją spada. Reasumując, jeśli liczba wierszy z brakującymi danymi jest niewielka w stosunku do całego zbioru, to usuwanie wierszy jest sensownym rozwiązaniem.\n\n* **uzupełnianie braków** - to procedura polegająca na zastępowaniu braków różnymi technikami. Jej niewątpliwą zaletą jest fakt posiadania kompletnych danych bez konieczności usuwania wierszy. Niestety wiąże się to również z pewnymi wadami. Zbiór posiadający wiele braków uzupełnianych nawet bardzo wyrafinowanymi metodami może cechować się zaniżoną wariancją poszczególnych cech oraz tzw. przeuczeniem.\n  - Uzupełnianie średnią - braki w zakresie danej zmiennej uzupełniamy średnią tej zmiennej przypadków uzupełnionych.\n  - Uzupełnianie medianą - braki w zakresie danej zmiennej uzupełniamy medianą tej zmiennej przypadków uzupełnionych.\n  - Wypełnianie zmiennych typu wyliczeniowego, logicznego lub znakowego odbywa się najczęściej przez dobranie w miejsce brakującej wartości, elementu powtarzającego się najczęściej wśród obiektów obserwowanych.\n  - Jeszcze innym sposobem imputacji danych są algorytmy oparte o metodę $k$-najbliższych sąsiadów. Istnieją również dużo bardziej złożone algorytmy imputacji danych oparte na bardziej wyrafinowanych technikach, takich jak: predykcja modelami liniowymi, nieliniowymi, analiza dyskryminacyjna, drzewa klasyfikacyjne.\n<br>\n\n## 3. Na co należy zwrócić uwagę podczas uzupełniania danych?\n\nImputacja danych z zastosowaniem pakietu mice wymaga podjęcia kilku decyzji przed przystąpieniem do uzupełniania danych:\n\n1. Czy dane są MAR (ang. Missing At Random) czy MNAR (ang. Missing Not At Random), co oznacza, że musimy się zastanowić jakie mogły być źródła braków danych, przypadkowe czy systematyczne?\n\n2. Należy się zdecydować na formę imputacji, określając strukturę zależności pomiędzy cechami oraz rozkład błędu danej cechy?\n\n3. Wybrać zbiór danych, który posłuży nam za predyktory w imputacji (nie mogą zawierać braków).\n\n4. Określenie, które niepełne zmienne są funkcjami innych wybrakowanych zmiennych.\n\n5. Określić w jakiej kolejności dane będą imputowane.\n\n6. Określić parametry startowe imputacji (liczbę iteracji, warunek zbieżności).\n\n7. Określić liczę imputowanych zbiorów.\n\n<br>\n\n## 4. Czym są braki MCAR, MAR, MNAR?\n\n- **MCAR** (ang. *Missing Completely At Random*) - z definicji to braki, których pojawienie się jest kompletnie losowe. Przykładowo gdy osoba poproszona o wypełnienie wieku w ankiecie będzie rzucać monetą czy wypełnić tą zmienną.\n\n- **MAR** (ang. *Missing At Random*) - oznacza, że obserwowane wartości i wybrakowane mają inne rozkłady ale da się je oszacować na podstawie danych obserwowanych. Przykładowo ciśnienie tętnicze u osób, które nie wypełniły tej wartości jest wyższe niż u osób, które wpisały swoje ciśnienie. Okazuje się, że osoby starsze z nadciśnieniem nie wypełniały ankiety w tym punkcie.\n\n- **MNAR** (ang. *Missing Not At Random*) - jeśli nie jest spełniony warunek MCAR i MAR, wówczas brak ma charakter nielosowy. Przykładowo respondenci osiągający wyższe zarobki sukcesywnie nie wypełniają pola “zarobki” i dodatkowo nie ma w ankiecie zmiennych, które pozwoliłyby nam ustalić, jakie to osoby.\n\n<br>\n\n## 5. Jakie znasz metody wnioskowania?\n\nData mining to zestaw metod pozyskiwania wiedzy na podstawie danych. Ową wiedzę zdobywamy w procesie wnioskowania na podstawie modeli. Wnioskowanie możemy podzielić na **dedukcyjne** i **indukcyjne**.\n\n- Z wnioskowaniem <u>dedukcyjnym</u> mamy do czynienia wówczas, gdy na podstawie obecnego stanu wiedzy potrafimy odpowiedzieć na postawione pytanie dotyczące nowej wiedzy, stosując reguły wnioskowania. \n\n- O wnioskowaniu <u>indukcyjnym</u> powiemy, że jest metodą pozyskiwania wiedzy na podstawie informacji ze zbioru uczącego. Znajduje ono szerokie zastosowanie w data mining i charakteryzuje się omylnością, ponieważ nawet najlepiej nauczony model na zbiorze uczącym nie zapewnia nam prawdziwości odpowiedzi w przypadku nowych danych, a jedynie je uprawdopodabnia. Esencją wnioskowania indukcyjnego w zakresie data mining, jest poszukiwanie na podstawie danych uczących modelu charakteryzującego się najlepszymi właściwościami predykcyjnymi i dającego się zastosować do zupełnie nowego zbioru danych.\n\n<br>\n\n## 6. Czym są obserwacja, atrybut, dziedzina, zbiór uczący i testowy?\n\n<u>Obserwacja</u> - każdy element dziedziny $x \\in X$. Obserwacją nazywać będziemy zarówno rekordy danych ze zbioru uczącego, jak i ze zbioru testowego.\n\n<u>Atrybut</u> - za jego pomocą (zestawu cech/ atrybutów) można opisać obserwację (każdy obiekt z dziedziny $x \\in X$). W notacji matematycznaj oznaczany przez $a: X \\rightarrow A$, gdzie $A$ jest przestrzenią wartości aatrybutów. Każda obserwacja $x$ posiadająca $k$ cech da się wyrazić wektorowo jako $(a_1(x),a_2(x),\\dots,a_k(x))$. \n\nDla większości algorytmów uczenia maszynowego wyrożnia się trzy typy atrybutów:\n\n- <u>nominalne</u> - posiadające skończoną liczbę stanów, które nie posiadają porządku (np. płeć, rasa)\n\n- <u>porządkowe</u> - posiadające skończoną liczbę stanów z zachowanie porządku (np. wykształcenie)\n\n- <u>ciągłe</u> - przyjmujące wartości numeryczne (np. wiek, wynagrodzenie)\n\nCzęsto jeden z atrybutów spełnia specjalną rolę, ponieważ stanowi realizację cechy, którą traktujemy jako wyjściową (ang. *target value attribute*). W tym przypadku powiemy o **nadzorowanym uczeniu maszynowym**. Jeśli zmiennej wyjściowej nie ma dziedzinie, to mówimy o **nienadzorowanym uczeniu maszynowym**.\n\n<u>Dziedzina</u> - zbiór wszystkich obiektów pozostających w zainteresowaniu badacza, będących przedmiotem wnioskowania, oznaczana najczęściej przez $X$. Przykładowo mogą to być zbiory osób, transakcji, urządzeń, instytucji, itp.\n\n<u>Zbiór uczący</u> - $T$ (ang. *training set*) podzbiór $D$ dzidziny $X$ (czyli $T \\subseteq D \\subseteq X$), gdzie zbiór $D$ stanowi ogół dostępnych obserwacji z dziedziny $X$. Zbiór uczący zawiera informacje dotyczące badane zjawiska na podstawie których, dokonuje się doboru modelu, selekcji cech istotnych z punktu widzenia własności predykcyjnych lub jakości klasyfikacji, budowy modelu oraz optymalizacji jego parametrów. W przypadku uczenia z nauczycielem (nadzorowanego) zbiór $T$ zawiera informację o wartościach atrybutów zmiennej wynikowej.\n\n<u>Zbiór testowy</u> $T'$ (ang. *test set*) zbiór będący dopełnieniem zbioru uczącego do zbioru $D$, czyli $T' = D \\backslash T$, stanowi zestaw danych służacy do oceny poprawności modelu nadzorowanego. W przypadku metod nienadorowanych raczej nie stosuje się zbiorów testowych\n\n<br>\n\n## 7. Czym jest nadmierne dopasowanie i niewystarczające dopasowanie modelu?\n\n<u>Nadmierne dopasowanie</u> - sytuacja, w której model wykazuje dobre charakterystyki jakości dopasowania na zbiorze uczącym ale słabe na testowym, mówimy wtedy o zjawisku przeuczenia modelu (ang. overfitting). Oznacza to, że model wskazuje predykcję poprawnie jedynie dla zbioru treningowego ale ma słaba własności generalizacyjne. Takie modele nie przedstawiają znaczącej wartości w odkrywaniu wiedzy w sposób indukcyjny.\n\n<u>Niewystarczające dopasowanie</u> - sytuacja w której parametry dopasowania modelu pokazują  słabe dopasowanie, zarówno na zbiorze uczącym, jak i testowym. Takie modele również nie są użyteczne w pozyskiwaniu wiedzu na temaet badanego zjawiska, a sytuację taką nazywamy niedouczeniem (ang. underfitting).\n\n<br>\n\n## 8. Wymień typy modeli uczenia maszynowego i krótki opis ich zasady działania.\n\n<u>**Modele regresyjne**</u>\nJednym z rodzajów zadań bazującym na wnioskowaniu indukcyjnym jest model regresyjny. Należy on do grupy metod nadzorowanych, których celem jest oszacowanie wartości cechy wyjściowej (która jest ilościowa) na podstawie zestawu predyktorów, które mogą być ilościowe i jakościowe. Uczenie takich modeli odbywa się poprzez optymalizację funkcji celu (np.$MSE$) na podstawie zbioru uczącego.\n\n<u>**Modele klasyfikacyjne**</u>\nPodobnie jak modele regresyjne, modele klasyfikacyjne należą do grupy metod nadzorowanego uczenia maszynowego. Ich zadaniem jest właściwa klasyfikacja obiektów na podstawie wielkości predyktorów. Odpowiedzią modelu jest zawsze cecha typu jakościowego, natomiast predyktory mogą mieć dowolny typ. Wyróżnia się klasyfikację dwu i wielostanową. Lista modeli realizujących klasyfikację binarną jest nieco dłuższa niż w przypadku modeli z wielostanową cechą wynikową. Proces uczenia modelu klasyfikacyjnego również opiera się na optymalizacji funkcji celu. Tym razem są to zupełnie inne miary jakości dopasowania (np. trafność, czyli odsetek poprawnych klasyfikacji).\n\n<u>**Modele grupujące**</u>\nBardzo szeroką gamę modeli nienadzorowanych stanowią metody analizy skupień. Ich zadaniem jest grupowanie obiektów w możliwie najbardziej jednorodne grupy, na podstawie wartości atrybutów poddanych analizie. Ponieważ są to metody “bez nauczyciela”, to ocena ich przydatności ma nieco inny charakter i choć istnieją różne wskaźniki jakości grupowania, to trudno tu o obiektywne wskazanie najlepszego rozwiązania.\n\n<br>\n\n## 9. Czym są drzewa decyzyjne, z jakich elementów się składają?\n\n<u>Drzewo decyzyjne</u> jest strukturą hierarchiczną przedstawiającą model klasyfikacyjny lub regresyjny. Stosowane są szczególnie często wówczas, gdy funkcyjna postać związku pomiędzy predyktorami a zmienną wynikową jest nieznana lub ciężka do ustalenia. Każde drzewo decyzyjne składa się z korzenia (ang. *root*), węzłów (ang. *nodes*) i liści (ang. *leaves*). Korzeniem nazywamy początkowy węzeł drzewa, z którego poprzez podziały (ang. *splits*) powstają kolejne węzły potomne. Końcowe węzły, które nie podlegają podziałom nazywamy liśćmi, a linie łączące węzły nazywamy gałęziami (ang. *branches*).\n\n<p style=\"color:#808080\">Jeśli drzewo służy do zadań klasyfikacyjnych, to liście zawierają informację o tym, która klasa w danym ciągu podziałów jest najbardziej prawdopodobna. Natomiast, jeśli drzewo jest regresyjne, to liście zawierają warunkowe miary tendencji centralnej (najczęściej średnią) wartości zmiennej wynikowej. Warunek stanowi szereg podziałów doprowadzający do danego węzła terminalnego (liścia). W obu przypadkach (klasyfikacji i regresji) drzewo “dąży” do takiego podziału by kolejne węzły, a co za tym idzie również liście, były ja najbardziej jednorodne ze względu na zmienną wynikową.</p>\n\n<br>\n\n## 10. Podaj rodzaje reguł podziału.\n\n\n\n<br>\n\n## 11. Opisz algorytm budowy drzewa decyzyjnego.\n\n1. Stwórz początkowy węzeł (korzeń) i oznacz go jako otwarty.\n\n2. Przypisz wszystkie możliwe rekordy do węzła początkowego.\n\n3. **Dopóki** istnieją otwarte węzły **wykonuj**:\n - wybierz węzeł $n$, wyznacz potrzebne statystyki opisowe zmiennej zależnej dla tego węzła i przypisz wartość docelową,\n - **jesli** kryterium zatrzymania podziału jest spełnione dla węzła $n$ , to oznacz go jako **zamknięty**,\n  - **w przeciwnym wypadku** wybierz podział $r$ elementów węzła $n$ i dla każdego podzbioru podziału stwórz węzeł niższego rzędy (potomka) $n_r$ oraz oznacz go jako *otwarty*,\n  - następnie przypisz wszystkie przypadki generowane podziałem $r$ do odpowiednich węzłów potomków $n_r$,\n  - oznacz węzeł $n$ jako **zamknięty**.\n\n<p style=\"color:#808080\">Sposób przypisywania wartości docelowej wiąże się ściśle z rodzajem drzewa. W drzewach regresyjnych chodzi o wyliczenie średniej lub mediany dla obserwacji ujętych w danym węźle. Natomiast w przypadku drzewa klasyfikacyjnego, wyznacza się wartości prawdopodobieństw przynależności obserwacji znajdującej się w danym węźle do poszczególnych klas.</p>\n\n<br>\n\n## 12. Jakie znasz reguły zatrzymania modelu drzewa decyzyjnego?\n\n<p style=\"color:#808080\">Kryterium zatrzymania jest warunkiem, który decyduje o tym, że dany węzeł uznajemy za zamknięty i nie dokonujemy dalszego jego podziału.</p> \n\nWyróżniamy następujące kryteria zatrzymania:\n\n1. <u>Jednorodność węzła</u> - w przypadku drzewa klasyfikacyjnego może zdarzyć się sytuacja, że wszystkie obserwacje węzła będą pochodziły z jednej klasy. Wówczas nie ma sensu dokonywać dalszego podziału węzła.\n\n2. <u>Węzeł jest pusty</u> - zbiór przypisanych obserwacji zbioru uczącego do $n$-tego węzła jest pusty.\n\n3. <u>Brak reguł podziału</u> - wszystkie reguły podziału zostały wykorzystane, zatem nie da się stworzyć potomnych węzłów, które charakteryzowałyby się większą homogenicznością.\n\n<p style=\"color:#808080\">4. <u>Wielkość drzewa</u> - węzeł potomny ustala się jako zamknięty, gdy długość ścieżki dojścia do niego przekroczy ustaloną wartość.</p> \n\n<p style=\"color:#808080\">Warunki ujęte w pierwszych dwóch kryteriach mogą być nieco złagodzone, poprzez zatrzymanie podziałów wówczas, gdy prawdopodobieństwo przynależenia do pewnej klasy przekroczy ustalony próg lub gdy liczebność węzła spadnie poniżej ustalonej wartości.</p> \n\n<br>\n\n## 13. Opisz jak się buduje reguły podziału w drzewach decyzyjnych.\n\n\n\n<br>\n\n## 14. Opisz przycinanie drzewa redukujące błąd.\n\nJedną ze strategii przycinania drzewa jest przycinanie redukujące błąd (ang. reduced error pruning). Polega ono na porównaniu błędów (najczęściej używana jest miara odsetka błędnych klasyfikacji lub MSE) liścia $l$ i węzła do którego drzewo przycinamy $n$ na całkiem nowym zbiorze uczącym $R$. Niech $e_R(l)$ i $e_R(n)$ oznaczają odpowiednio błędy liścia i węzła na zbiorze $R$. Przez błąd węzła rozumiemy błąd pod-drzewa o korzeniu w węźle $n$. Wówczas jeśli zachodzi warunek $$e_R(l)\\leq e_R(n)$$ to zaleca się zastąpić węzeł $n$ liściem $l$.\n\n<br>\n\n## 15. Opisz przycinanie drzewa minimalizujące błąd.\n\n<!-- nagranie wykładu 21.03.2023 0:37:00 -->\n\nPrzycinanie minimalizujące błąd opiera się na spostrzeżeniu, że błąd drzewa przyciętego charakteryzuje się zbyt pesymistyczną oceną i dlatego wymaga korekty. Węzeł drzewa klasyfikacyjnego $n$ zastępujemy liściem $l$, jeśli $$\\hat e_T(l)\\leq \\hat e_T(n)$$ gdzie <br>\n$\\hat e_T(n)$ - miara błędu poddrzewa stojącego pod węzłem $n$ <br>\n$\\hat e_T(l)$ - miara błędu na liściu liczona na podstwaie prawdopodobieństwa przynależności do danej klasy\n<p style=\"color:#808080\">$\\hat e$ - szacunek błędu </p>\n\nW przypadku drzewa regresyjnego znajdujemy wiele analogii, ponieważ jeśli dla pewnego zbioru rekordów $T$ spełniony jest warunek $$\\text{mse}_T(l) \\leq \\text{mse}_T(n)$$ gdzie <br> $l$ i $n$ oznaczają odpowiednio liść i węzeł, <br> \n\nto wówczas zastępujemy węzeł $n$ przez liść $l$.\n\n<br>\n\n## 16. Opisz przycinanie drzewa ze względu na współczynnik złożoności drzewa.\n\nPrzycinanie ze względu na współczynnik złożoności drzewa (ang. *cost-complexity pruning*) polega na wprowadzeniu “kary” za zwiększoną złożoność drzewa. Drzewa klasyfikacyjne przycinamy gdy spełniony jest warunek $$e_T(l) \\leq e_T(n) + \\alpha C(n)$$ gdzie <br> $\\alpha$ jest parametrem wagi kary za złożoność drzewa, <br> $C(n)$ oznacza złożoność drzewa mierzoną liczbą liści\n\nWspomniane kryterium przycięcia dla drzew regresyjnych bazuje na względnym błędzie średnio-kwadratowym (ang. *relative square error*)\n\n<br>\n\n## 17. Opisz zalety i wady drzew decyzyjnych.\n\n<u>Zalety</u>:\n\n  + łatwe w interpretacji;\n\n  + nie wymagają żmudnego przygotowania danych (brak standaryzacji, wprowadzania zmiennych binarnych, dopuszcza występowanie braków danych);\n\n  + działa na obu typach zmiennych - jakościowych i ilościowych;\n\n  + dopuszcza nieliniowość związku między zmienną wynikową a predyktorami;\n\n  + odporny na odstępstwa od założeń;\n\n  + pozwala na obsługę dużych zbiorów danych.\n  \n<u>Wady</u>:\n  \n  + brak jawnej postaci zależności;\n  \n  + zależność struktury drzewa od użytego algorytmu;\n\n  + przegrywa jakością predykcji z innymi metodami nadzorowanego uczenia maszynowego.\n\n<br>\n\n## 18. Opisz zasadę działania modeli bagging.\n\nBagging ma na celu zmniejszenie wariancji modelu pojedynczego drzewa. Podobnie jak technika bootstrap, w której statystyki są wyliczane na wielu próbach pobranych z tego samego rozkładu (próby), w metodzie bagging losuje się wiele prób ze zbioru uczącego (najczęściej poprzez wielokrotne losowanie próby o rozmiarze zbioru uczącego ze zwracaniem), a następnie dla każdej próby bootstrapowej buduje się drzewo. W ten sposób otrzymujemy $B$ drzew decyzyjnych $\\hat f ^1 (x), \\hat f ^2 (x), \\dots, \\hat f ^B (x)$. Na koniec poprzez uśrednienie otrzymujemy model charakteryzujący się większą precyzją $$\\hat f_{\\text{bag}}(x) = \\frac{1}{B}\\sum\\limits^{B}_{b=1}\\hat f ^b (x)$$ Ponieważ podczas budowy drzew na podstawie prób bootstrapowych nie kontrolujemy złożoności, to w rezultacie każde z drzew może charakteryzować się dużą wariancją. Poprzez uśrednianie wyników pojedynczych drzew otrzymujemy mniejsze obciążenie ale również przy dostatecznie dużej liczbie prób ($B$ często liczy się w setkach, czy tysiącach) zmniejszamy wariancję “średniej” predykcji z drzew. Oczywiście metodę tą trzeba dostosować do zadań klasyfikacyjnych, ponieważ nie istnieje średnia klasyfikacji z wielu drzew. W miejsce średniej stosuje się modę, czyli wartość dominującą.\n\n<p style=\"color:#808080\">W przypadku metody bagging interpretacja jest znacznie utrudniona, ponieważ jej wynik składa się z agregacji wielu drzew. Można natomiast ocenić ważność predyktorów (ang. *variable importance*). I tak, przez obserwację spadku $RSS$ dla baggingu regresyjnego przy zastosowaniu danego predyktora w podziałach drzewa i uśrednieniu wyniku otrzymamy wskaźnik ważności predyktora dużo lepszy niż dla pojedynczego drzewa. W przypadku baggingu klasyfikacyjnego w miejsce $RSS$ stosujemy *indeks Gini’ego*</p>\n\n<br>\n\n## 19. Opisz zasadę działania lasów losowych.\n\nLasy losowe są uogólnieniem metody bagging, polegającą na losowaniu dla każdego drzewa wchodzącego w skład lasu $m$ redyktorów spośród $p$ dostępnych, a następnie budowaniu drzew z wykorzystaniem tylko tych predyktorów. Dzięki temu za każdy razem drzewo jest budowane w oparciu o nowy zestaw cech (najczęściej przyjmujemy $m = \\sqrt{p}$.  W przypadku modeli bagging za każdym razem najsilniejszy predyktor wchodził w skład zbioru uczącego, a co za tym idzie również uczestniczył w tworzeniu reguł podziału. Wówczas wiele drzew zawierało reguły stosujące dany atrybut, a wtedy predykcje otrzymywane za pomocą drzew były skorelowane. Dlatego nawet duża liczba prób bootstrapowych nie zapewniała poprawy precyzji.\n\n<br>\n\n## 20. Opisz zasadę działania metody boosting.\n\nW metodzie boosting nie stosuje się prób bootstrapowych ale odpowiednio modyfikuje się drzewo wyjściowe w kolejnych krokach na tym samym zbiorze uczącym.\n\nAlgorytm dla drzewa regresyjnego jest następujący:\n\n1. Ustal $\\hat f(x) = 0$ i $r_i = y_i$ dla każdego $i$ w zbiorze uczącym.\n\n2. Dla $b = 1,2,\\dots ,B$ powtarzaj: \n\n  - naucz drzewo $\\hat f ^b$ o $d$ regułach podziału (czyli $d+1$ liściach) na zbiorze $(X_i,r_i)$,\n  \n  - zaktualizuj drzewo do nowej \"skurczonej\" wersji $\\hat f(x) \\leftarrow \\hat f(x) + \\lambda \\hat f^b (x)$,\n  \n  - zaktualizuj reszty $r_i \\leftarrow r_i - \\lambda \\hat f^b (x_i)$,\n  \n3. Wyznacz boosted model $\\hat f(x) = \\sum \\limits ^B _{b=1} \\lambda \\hat f^b(x)$\n\n<br>\n\nUczenie drzew klasyfikacyjnego metoda boosting przebiega w podobny sposób. Wynik uczenia drzew metodą boosting zależy od trzech parametrów:\n\n1. Liczby drzew $B$. W przeciwieństwie do metody bagging i lasów losowych, zbyt duże $B$ może doprowadzić do przeuczenia modelu. $B$ ustala się najczęściej na podstawie walidacji krzyżowej.\n\n2. Parametru “kurczenia” (ang. *shrinkage*) $\\lambda$.Kontroluje on szybkość uczenia się kolejnych drzew. Typowe wartości $\\lambda$ to $0.01$ lub $0.001$. Bardzo małe $\\lambda$ może wymagać dobrania większego $B$, aby zapewnić dobrą jakość predykcyjną modelu.\n\n3. Liczby podziałów w drzewach $d$, która decyduje o złożoności drzewa. Bywa, że nawet $d=1$ daje dobre rezultaty, ponieważ model wówczas uczy się powoli.\n\n\n<br>\n\n## 21. Czym są klasyfikatory liniowe?\n\nObszerną rodzinę klasyfikatorów stanowią modele liniowe (ang. *linear classification models*). Klasyfikacji w tej rodzinie technik dokonuje się na podstawie modeli funkcji kombinacji liniowej predyktorów. Jest to ujęcie parametryczne, w którym klasyfikacji nowej wartości dokonujemy na podstawie atrybutów obserwacji i wektora parametrów. Uczenie na podstawie zestawu treningowego polega na oszacowaniu parametrów modelu. W odróżnieniu od metod nieparametrycznych postać modelu tym razem jest znana. Każdy klasyfikator liniowy skład się z funkcji wewnętrznej (ang. *inner representation function*) i funkcji zewnętrznej (ang. *outer representation function*). \n\nPierwsza jest funkcją rzeczywistą parametrów modelu i wartości atrybutów obserwacji $$g(x) = F(\\text a(x), \\text w) = \\sum \\limits ^p _{i=0} w_i a_i (x) = \\text w \\circ \\text a(x), \\quad \\text{przyjmując, że }\\;a_0(x) = 1$$\n\nFunkcja zewnętrzna przyporządkowuje binarnie klasy na podstawie wartości funkcji wewnętrznej. Istnieją dwa główne typy tych klasyfikacji:\n\n<ul>\n\n  - brzegowa - przyjmujemy, że funkcje wewnętrzne tworzą granice zbiorów obserwacji różnych klas,\n\n  - probabilistyczna - bazująca na tym, że funkcje wewnętrzne mogą pośrednio wykazywać prawdopodobieństwo przynależności do danej klasy.\n\n  \nPierwsza dzieli przestrzeń obserwacji za pomocą hiperpłaszczyzn na obszary jednorodne pod względem przynależności do klas. Druga jest próbą parametrycznej reprezentacji prawdopodobieństw przynależności do klas.\n\n<ul>\n\nKlasyfikacji na podstawie prawdopodobieństw można dokonać na różne sposoby, stosując:\n\n  - największe prawdopodobieństwo,\n\n  - funkcję najmniejszego kosztu błędnej klasyfikacji,\n  \n  - krzywych ROC (ang. *Receiver Operating Characteristic* - o tym później).\n\n</ul>\n\nPodejście brzegowe lub probabilistyczne prowadzi najczęściej do dwóch typów reprezentacji funkcji zewnętrznej:\n\n  - reprezentacji progowej (ang. *threshold representation*) - najczęściej przy podejściu brzegowym,\n  \n  - reprezentacji logistycznej (ang. *logit representation*) - przy podejściu probabilistycznym.\n\n</ul>\n\n\n<p style=\"color:#808080\"!important> Wady klasyfikatorów liniowych\n\n  <li style=\"color:#808080\">tylko w przypadku prostych funkcji wewnętrznych jesteśmy w stanie ocenić wpływ poszczególnych predykorów na klasyfikację,</li>\n  \n  <li style=\"color:#808080\">jakość predykcji zależy od doboru funkcji wewnętrznej (liniowa w ścisłym sensie jest najczęściej niewystarczająca),</li>\n  \n  <li style=\"color:#808080\">nie jest w stanie klasyfikować poprawnie stanów (nie jest liniowo separowalna) w zagadnieniach typu XOR.</li> </p>\n\n<br>\n\n## 22. Opisz reprezentację progową.\n\nW przypadku klasyfikacji dwustanowej, dziedzina jest dzielona na dwa regiony (pozytywny i negatywny) poprzez porównanie funkcji zewnętrznej z wartością progową. Bez straty ogólności można sprawić, że będzie to wartość $0$ $$h(x) = H(g(x)) = \\begin{cases}1, \\quad \\text{jeśli } \\, g(x) \\geq 0 \\\\ 0, \\quad \\text{w przeciwnym przypadku}\\end{cases}$$ Czasami używa się parametryzacji $\\{-1,1\\}$. Przez porównanie $g(x)$ z $0$ definiuje się hiperpłaszczyznę w $p$-wymiarowej przestrzeni, która rozdziela dziedzinę na regiony pozytywne i negatywne. W tym ujęciu mówimy o liniowej separowalności obserwacji różnych klas, jeśli istnieje hiperpłaszczyzna je rozdzielająca.\n\n<br>\n\n## 23. Opisz reprezentację logitową.\n\nNajbardziej popularną reprezentacją parametryczną stosowaną w klasyfikacji jest reprezentacja logitowa $$P(y=1|x) = \\frac{e^{g(x)}}{e^{g(x)}+1}$$ \n<ul>\nWówczas $g(X)$ nie reprezentuje bezpośrednio $P(y=1|x)$ ale jego logit $$g(x) = \\text{logit}(P(y=1|x))$$ \n<ol>\ngdzie <br>\n$\\text{logit}(p)=\\text{ln}\\left(\\frac{p}{1-p}\\right)$ <br>\nDlatego właściwa postać reprezentacji jest następująca $$P(y=1|x) = \\text{logit}^{-1}(g(x))$$\n</ol>\nW ten sposób reprezentacja logitowa jest równoważna reprezentacji progowej, ponieważ $$g(x) = \\text{ln}\\left(\\frac{P(y=1|x)}{1-P(y=1|x)}\\right) = \\text{ln}\\left(\\frac{P(y=1|x)}{P(y=0|x)}\\right) > 0$$\n</ul>\n\nJednak zaletą reprezentacji logitowej, w porównaniu do progowej, jest to, że można wyznaczyć prawdopodobieństwa przynależności do obu klas. W przypadku klasyfikacji wielostanowej uczymy tyle funkcji $h$ ile jest klas.\n\n<br>\n\n## 24. Opisz konstrukcję liniowych modeli dyskryminacyjnych (Fishera lub Welcha).\n\n\n\n<br>\n\n## 25. Czym są klasyfikatory bayesowskie? Zalety i wady?\n\nCałą gamę klasyfikatorów opartych na twierdzeniu Bayesa nazywać będziemy bayesowskimi. $$P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$$ gdzie <br> $P(B)>0$\n\nBayesowskie reguły podejmowania decyzji dały podstawy takich metod jak:\n\n  - liniowa analiza dyskryminacyjna,\n  \n  - kwadratowa analiza dyskryminacyjna.\n  \nW ustaleniu klasyfikatora bayesowskiego będzie nam przyświecała cały czas ta sama reguła: *jeśli znam wartości cech charakteryzujących badane obiekty oraz klasy do których należą (w próbie uczącej), to na ich podstawie mogę wyznaczyć miary prawdopodobieństw a posteriori, które pomogą mi w ustaleniu klasy do której należy nowy testowy element.*\n\n<br>\n\n## 26. Opisz zasadę działania naiwnego klasyfikatora Bayesa.\n\nW naiwnym klasyfikatorze Bayesa zakłada się niezależność warunkową poszczególnych atrybutów względem klasy do której ma należeć (wg hipotezy) obiekt. Założenie to często nie jest spełnione i stąd nazwa przymiotnik *“naiwny”*.\n\n<p style=\"color:#808080\">\nDefinicja naiwnego klasyfikatora bayesowskiego różni się od klasyfikatora MAP tylko podejściem do prawdopodobieństwa a posteriori.\n</p>\n\n$$h_{\\text{NB}} = \\text{arg} \\max\\limits_{h_j \\in\\mathbf{H}}P(h_j)\\prod\\limits^p_{i=1}P(a_i=v_i|h_j)$$ gdzie <br>\n$h_j$ oznacza hipotezę (decyzję), że badany obiek należy do $j$-tej klasy, <br>\n$P(h_j) = P_T(h_j) =\\frac{|T^j|}{|T|}$ jest prawdopodobieństwiem *a priori* zajścia hipotezy $h_j$,<br>\n$P(a_i=v_i|h_j) = P_{T^j}(a_i=v_i) = \\frac{|T^j_{a_i=v_i}|}{|T|}$ jest prawdopodobieństwem *a posteriori* dla *i*-tego atrybutu.\n\n<details>\n\n<summary></summary>\n\n<p style=\"color:#808080\">\n$T$ - zbiór danych uczących (treningowych), <br>\n$T^j$ - zbiór danych uczących dla których przyjęliśmy decyzję o przynależności do $j$-tej klasy, <br>\n$T^j_{a_i=v_i}$ - zbiór danych uczących o wartości atrybutu $a_i$ równej $v$ i $j$-tej klasy, <br>\n$\\mathbf{H}$ - przestrzeń hipotez, <br>\n$c$ - prawdziwy stan obiektu.\n</p>\n\n</details>\n\nZarówno prawdopodobieństwo a priori jak i a posteriori są wyznaczane na podstawie próby.\n\n<br>\n\nZalety:\n\n  - prostota konstrukcji i prosty algorytm,\n\n  - jeśli jest spełnione założenie warunkowej niezależności, to ten klasyfikator działa szybciej i czasem lepiej niż inne metody klasyfikacji,\n  \n  - nie potrzebuje dużych zbiorów danych do estymacji parametrów.\n  \nWady:\n\n  - często nie spełnione założenie o warunkowej niezależności powoduje obciążenie wyników,\n\n  - brak możliwości wprowadzania interakcji efektów kilku zmiennych,\n\n  - potrzebuje założenia normalności warunkowych gęstości w przypadku ciągłych atrybutów,\n\n  - często istnieją lepsze klasyfikatory.\n\n<br>\n\n## 27. Opisz regułę działania modeli kNN.\n\nTechnika $k$ najbliższych sąsiadów (ang.*$k$-Nearest Neighbors*) przewiduje wartość zmiennej wynikowej na podstawie $k$ najbliższych obserwacji zbioru uczącego. W przeciwieństwie do modeli liniowych, nie posiada ona jawnej formy i należy do klasy technik nazywanych czarnymi skrzynkami (ang. *black box*). Może być wykorzystywana, zarówno do zadań klasyfikacyjnych, jak i regresyjnych. W obu przypadkach predykcja dla nowych wartości predyktorów przebiega podobnie.\n\nNiech $x_0$  będzie obserwacją, dla której poszukujemy wartości zmiennej wynikowej $y_0$. Na podstawie zbioru obserwacji $x \\in T$ zbioru uczącego wyznacza się $k$ najbliższych sąsiadów *(metrykę można wybierać dowolnie, choć najczęściej jest to metryka euklidesowa)*, gdzie $k$ jest z góry ustaloną wartością. Następnie, jeśli zadanie ma charakter klasyfikacyjny, to $y_0$ przypisuje się modę zmiennej wynikowej obserwacji będących $k$ ajbliższymi sąsiadami. W przypadku zadań regresyjnych $y_0$ przypisuje się średnią lub medianę.\n\nOlbrzymie znaczenie dla wyników predykcji na podstawie metody *kNN* ma dobór metryki. Nie istnieje obiektywna technika wyboru najlepszej metryki, dlatego jej doboru dokonujemy metodą prób i błędów. Należy dodatkowo pamiętać, że wielkości mierzone $x$ mogą się różnić zakresami zmienności, a co za tym idzie, mogą znacząco wpłynąć na mierzone odległości pomiędzy punktami. Dlatego zaleca się standaryzację zmiennych przed zastosowaniem metody *kNN*.\n\nKolejnym parametrem, który ma znaczący wpływ na predykcję, jest liczba sąsiadów $k$. Wybór zbyt małej liczby $k$ może doprowadzić do przeuczenia modelu, z kolei zbyt duża liczba sąsiadów powoduje obciążenie wyników. Dopiero dobór odpowiedniego $k$ daje model o stosunkowo niskiej wariancji i obciążeniu. Najczęściej liczby $k$ poszukujemy za pomocą próbkowania.\n\n<br>\n\n## 28. Czym są uogólnione modele addytywne?\n\n\n\n<br>\n\n## 29. Opisz zasadę działania modeli SVM dla dwóch klas liniowo separowalnych.\n\n<p style=\"color:#808080\">\nMetoda wektorów nośnych (ang. *Support Vector Machines*) to metoda klasyfikacji obserwacji na podstawie cech (atrybutów). Jest techniką nadzorowaną tzn., że w próbie uczącej występują zarówno cechy charakteryzujące badane obiekty jak i ich przynależność do klasy.\n</p>\n\n<center>\n![Przykład prostych separujących obiekty obu grup](obrazki/SVM1.png)\n</center>\n\nIstotą tej metody jest znalezienie wektorów nośnych, definiujących hiperpowierzchnie optymalnie separujące obiekty w homogeniczne grupy.\n\nNiech $D$ będzie zbiorem $n$ punktów w $d$-wymiarowej przestrzeni określonych następująco $(\\vec{x_i}, y_i)$, $i=1,\\dots,d$, gdzie $y_i$ przyjmuje wartości $-1$ lub $1$ w zależności od tego do której grupy należy (zakładamy istnienie tylko dwóch grup). Poszukujemy takiej hiperpłaszczyzny, która maksymalizuje margines pomiędzy punktami obu klas w przestrzeni cech $\\vec x$.\n\n<center>\n![Płaszczyzna najlepiej rozdzielająca obiekty obu grup (białe i czarne kropki) wraz z prostymi wyznaczającymi maksymalny margines separujący obie grupy](obrazki/SVM2.png){width=50%}\n</center>\n\nMargines ten jest określany jako najmniejsza odległość pomiędzy hiperpłaszczyzną i elementami z każdej z grup. <br>\nDowolna hiperpłaszczyzna może być zapisana równaniem $\\vec w \\vec x - b = 0$ gdzie <br> $\\vec w$ jest waktorem normalnym do hiperpłaszczyzny. <br>\nJeśli dane są liniowo separowalne to, można wybrać takie dwie hiperpłaszczyzny, że odległość pomiędzy nimi jest największa. <br>\nRównania tych hiperpłaszczyzn dane są wzorami $$\\vec w \\vec x - b = 1, \\quad \\vec w \\vec x - b = -1$$ Odległość pomiędzy tymi hiperpłaszczyznami wynosi $\\frac{2}{||\\vec w||}$. Zatem żeby zmaksymalizować odległość pomiędzy hiperpłaszczyznami (margines) musimy zminimalizować $\\frac{||\\vec w||}{2}$. <br> Dodatkowo, żeby nie pozwolić aby punkty wpadały do marginesu musimy nałożyć dodatkowe ograniczenia $$\\begin{align}\n\\vec w \\vec x_i - b & \\geq 1, \\quad  y_i  = 1 \\\\ \n\\vec w \\vec x_i - b & \\leq -1, \\;  y_i  = -1\n\\end{align}$$ Co można zapisać $y_i(\\vec w \\vec x_i - b \\geq 1), \\; 1\\leq i \\leq n$.\n\nZatem $\\vec w$ i $b$ minimalizujące $||\\vec w||$ przy jednoczesnym spełnieniu warunku definiują klasyfikator postaci $$\\vec x \\rightarrow \\text{sgn}(\\vec w \\vec x - b)$$.\nZ racji, że $||\\vec w||$ jest określona jako pierwiastek sumy kwadratów poszczególnych współrzędnych wektora, to częściej w minimalizacji stosuje się$||\\vec w||^2$.\n\nSformułowany powyżej problem należy do grupy optymalizacji funkcji kwadratowej przy liniowych ograniczeniach. Rozwiązuje się go metodą mnożników Lagrange’a. $$L(\\vec w,b,\\alpha) = \\frac{1}{2}||\\vec w||^2 - \\sum\\limits^n_{i=1}\\alpha_i(y_i(\\vec w \\vec{x_i} - b) - 1)$$ gdzie <br> $\\alpha_i$ są mnożnikami Lagrange'a.\n\n<br>\n\n## 30. Na czym polega metoda jądrowa w SVM?\n\nMetoda jądrowa pozwala ona na nieliniowy kształt brzegu obszaru decyzyjnego. \n\nZasada działania polega na znalezieniu takiego jądra przekształcenia (ang. *kernel*) $\\phi$, które odwzoruje przestrzeń $d$-wymiarową w $d'$-wymiarową, gdzie $d'>d$ taką, że $D_\\phi=\\{\\phi(\\vec{x_i}), y_i\\}$ jest możliwie jak najbardziej separowalna. \n\n<center>\n![Przykład zastosowania takiego przekształcenia jądrowego aby z sytuacji braku liniowej separowalności do niej doprowadzić](obrazki/SVM3.png)\n</center>\n\nDla funkcji jądrowej określonej wzorem $k(\\vec{x_i},\\vec{x_j})=\\phi(\\vec{x_i})\\phi(\\vec{x_j})$ minimalizujemy wyrażenie $$L(\\alpha_i) = \\sum\\limits^n_{i=1}\\alpha_i+\\frac{1}{2}\\sum\\limits^n_{i=1}\\sum\\limits^n_{j=1}\\alpha_i\\alpha_jy_iy_jk(\\vec{x_i},\\vec{x_j})$$ przy warunkach $$\\sum\\limits^n_{n=1}\\alpha_iy_i =0, \\quad0\\leq \\alpha_i\\leq \\frac{1}{2n\\lambda}$$\n\nNajczęściej stosowanymi funkcjami jądrowymi są:\n\n - wialomianowa\n \n - gaussowska\n \n - Laplace'a\n \n - hiperboliczna\n \n - sigmoidalna\n \n - Bessel'a\n \n - ANOVA\n \n - sklejana dla jednowymiarowej przestrzeni\n \nW przypadku braku wiedzy o danych funkcja gaussowska, Laplace’a i Bessel’a są zalecane.\n\n\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"Eksploracja_egzamin.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.475","theme":{"light":"pulse","dark":"darkly"}},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"Eksploracja_egzamin.pdf"},"language":{},"metadata":{"block-headings":true,"documentclass":"scrreprt"},"extensions":{"book":{}}}}}